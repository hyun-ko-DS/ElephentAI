# ai_pricer_sameitem_price.py
import os, io, csv, re, json, base64
from typing import Dict, Optional, Tuple, List

import numpy as np
from PIL import Image, ImageEnhance

import torch
from transformers import CLIPProcessor, CLIPModel

from dotenv import load_dotenv
from anthropic import Anthropic

# ======================= ì‚¬ìš©ì ì„¤ì • =======================
IMAGE_PATH   = r"C:\Users\031\Desktop\predict_price\ì¶”ê°€\add_0030.webp"

FEATURES_NPY = r"C:\Users\031\Desktop\predict_price\toys_index\used_features_large_patch14.npy"
PATHS_NPY    = r"C:\Users\031\Desktop\predict_price\toys_index\used_paths_large_patch14.npy"
MODEL_NAME   = "openai/clip-vit-large-patch14"
TOPK         = 6   # ë„‰ë„‰íˆ ë½‘ê³  Top3ë§Œ ì‚¬ìš©

# paths.npy ì—ì„œ basenameë§Œ ì‚¬ìš©í•´, ì‹¤ì œ ì´ë¯¸ì§€ëŠ” ì´ í´ë”ì—ì„œ ì°¾ìŠµë‹ˆë‹¤.
IMAGE_BASE_DIR = r"C:\Users\031\Desktop\predict_price\used\used"

# CSVì—ì„œ íŒŒì¼ëª…â†’ê°€ê²© ë§¤í•‘
JOONGNA_CSV  = r"C:\Users\031\Desktop\predict_price\products_info.csv"
FILENAME_COL = "thumbnail_filename"
PRICE_COL    = "price"
PRODUCT_COL  = "title"   # (ì„ íƒ: ì—†ìœ¼ë©´ ìë™ ê±´ë„ˆëœ€)

NORMALIZE_FILENAMES = True
CLAUDE_MODEL = "claude-sonnet-4-20250514"
# ==========================================================
load_dotenv()

# ----------------------- ìœ í‹¸ -----------------------
def _parse_price_to_int(text: str) -> Optional[int]:
    if text is None: return None
    t = str(text).strip().replace(",", "").replace("ì›", "").replace("KRW", "")
    if not re.search(r"[0-9]", t): return None
    try:
        return int(float(t))
    except ValueError:
        digits = "".join(ch for ch in t if ch.isdigit())
        return int(digits) if digits else None

def _norm_name(path_or_name: str) -> str:
    name = os.path.basename(str(path_or_name)).strip()
    return name.lower() if NORMALIZE_FILENAMES else name

def load_meta_maps(csv_path, filename_col, price_col, product_col=None) -> Tuple[Dict[str,int], Optional[Dict[str,str]]]:
    if not os.path.isfile(csv_path):
        return {}, None
    encodings = ("utf-8-sig", "utf-8", "cp949")
    last_err = None
    for enc in encodings:
        try:
            with open(csv_path, "r", encoding=enc, newline="") as f:
                reader = csv.DictReader(f)
                fields = reader.fieldnames or []
                if filename_col not in fields or price_col not in fields:
                    raise KeyError(f"CSVì— '{filename_col}', '{price_col}' ì»¬ëŸ¼ì´ í•„ìš”. í˜„ì¬: {fields}")
                price_map, title_map = {}, {}
                has_title = product_col in fields if product_col else False
                for row in reader:
                    raw = row.get(filename_col, "")
                    fname = _norm_name(raw)
                    if not fname: continue
                    price = _parse_price_to_int(row.get(price_col))
                    if price is not None: price_map[fname] = price
                    if has_title: title_map[fname] = str(row.get(product_col, "")).strip()
                return price_map, (title_map if has_title else None)
        except UnicodeDecodeError as e:
            last_err = e
            continue
    raise RuntimeError(f"CSV ì¸ì½”ë”© ì‹¤íŒ¨(ì‹œë„: {encodings}) ì›ì¸: {last_err}")

# ----------------------- CLIP ì„ë² ë”© -----------------------
def load_model(model_name: str, device: torch.device):
    model = CLIPModel.from_pretrained(model_name).to(device)
    processor = CLIPProcessor.from_pretrained(model_name)
    model.eval()
    return model, processor

def embed_image(model, processor, img_path, device) -> np.ndarray:
    image = Image.open(img_path).convert("RGB")
    with torch.no_grad():
        inputs = processor(images=image, return_tensors="pt").to(device)
        feat = model.get_image_features(**inputs)
        feat = feat / feat.norm(p=2, dim=-1, keepdim=True)
    return feat.cpu().numpy().astype("float32").flatten()

# ----------------------- ì´ë¯¸ì§€ â†’ Base64 -----------------------
def _resize_to_jpeg_bytes(img: Image.Image, max_side=1024, enhance=False) -> bytes:
    w,h = img.size
    scale = min(1.0, max_side / max(w,h))
    if scale < 1.0: img = img.resize((int(w*scale), int(h*scale)), Image.Resampling.LANCZOS)
    if enhance:
        img = ImageEnhance.Contrast(img).enhance(1.3)
        img = ImageEnhance.Sharpness(img).enhance(1.6)
        img = ImageEnhance.Brightness(img).enhance(1.05)
    buf = io.BytesIO(); img.save(buf, format="JPEG", quality=92); return buf.getvalue()

def _path_to_b64(path: str, enhance=False) -> str:
    img = Image.open(path).convert("RGB")
    return base64.b64encode(_resize_to_jpeg_bytes(img, enhance=enhance)).decode("utf-8")

# ----------------------- ë™ì¼í’ˆ íŒì • í”„ë¡¬í”„íŠ¸ -----------------------
SAME_ITEM_PROMPT = """
You are a product matcher. For each CANDIDATE photo, decide if it is the SAME PRODUCT/MODEL as the QUERY photo.
Focus on brand/series/character, mold/shape, printed patterns, colorway, scale/size cues, accessories/parts, packaging text or set ID.
Do NOT be fooled by pose/angle/lighting. If unsure, answer false.

Return STRICT JSON ONLY, exactly this schema:
{"same": [true, true, true]}

Rules:
- The array order MUST match the order of the CANDIDATE blocks you receive.
- "same" means same model/edition (not just same category/character).
- Variant/limited/colorway/set-ID mismatch => false.
- STRICT JSON only. No extra text.
"""

# ----------------------- Claude í˜¸ì¶œ ë˜í¼ -----------------------
class SameItemJudgeClaude:
    def __init__(self, client: Anthropic):
        self.client = client

    def judge(self, query_path: str, candidates: List[dict]) -> List[bool]:
        contents = [{"type":"text","text": SAME_ITEM_PROMPT}]
        contents.append({"type":"text","text": f"QUERY: {os.path.basename(query_path)}"})
        contents.append({"type":"image","source":{
            "type":"base64","media_type":"image/jpeg","data": _path_to_b64(query_path)
        }})

        for c in candidates:
            meta_line = f"CANDIDATE rank={c['rank']} | file={c['filename']} | sim={c['sim']:.4f}"
            if c.get("title"): meta_line += f" | title={c['title']}"
            contents.append({"type":"text","text": meta_line})
            contents.append({"type":"image","source":{
                "type":"base64","media_type":"image/jpeg","data": _path_to_b64(c['resolved_path'])
            }})

        msg = self.client.messages.create(
            model=CLAUDE_MODEL,
            max_tokens=100,  # ì¶œë ¥ì´ ë§¤ìš° ì§§ìŒ
            temperature=0.1,
            system="Return STRICT JSON. No extra text.",
            messages=[{"role":"user","content": contents}]
        )

        raw = "".join(b.text for b in msg.content if hasattr(b, "text")).strip()
        if raw.startswith("```"):
            raw = raw.strip("`").replace("json","",1).strip()

        try:
            data = json.loads(raw)
            same = list(data.get("same", []))
            same = [bool(x) for x in same][:len(candidates)]
            if len(same) < len(candidates):
                same += [False] * (len(candidates) - len(same))
        except Exception:
            same = [False] * len(candidates)
        return same

# ----------------------- ìœ ì‚¬ë„ ê²€ìƒ‰ -----------------------
def similar_search(query_img: str, feats_npy: str, paths_npy: str,
                   model_name: str, topk: int=6):
    if not os.path.isfile(query_img): raise FileNotFoundError(f"IMAGE_PATH not found: {query_img}")
    if not os.path.isfile(feats_npy) or not os.path.isfile(paths_npy):
        raise FileNotFoundError("features/paths npy í•„ìš”")

    feats = np.load(feats_npy).astype("float32")
    paths = np.load(paths_npy, allow_pickle=True)
    if feats.ndim!=2 or feats.shape[0]!=len(paths): raise ValueError("features/paths í¬ê¸° ë¶ˆì¼ì¹˜")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model, processor = load_model(model_name, device)

    q = embed_image(model, processor, query_img, device)
    q = q / (np.linalg.norm(q)+1e-9)
    feats = feats / (np.linalg.norm(feats,axis=1,keepdims=True)+1e-9)

    sims = feats @ q
    top_idx = np.argsort(sims)[::-1][:topk]

    entries=[]
    for rank,i in enumerate(top_idx, start=1):
        p = str(paths[i])
        entries.append({
            "rank": rank,
            "path": p,                                  # ì›ë˜ ê²½ë¡œ ë¬¸ìì—´
            "filename": _norm_name(os.path.basename(p)),# basenameë§Œ ì¶”ì¶œ(ë§¤í•‘/ì¬í•´ê²° í‚¤)
            "sim": float(sims[i])
        })
    return entries

# ----------------------- ê²½ë¡œ ì¬í•´ê²° -----------------------
def resolve_to_base_dir(filename: str, base_dir: str) -> str:
    resolved = os.path.join(base_dir, os.path.basename(filename))
    if not os.path.isfile(resolved):
        raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {resolved}")
    return resolved

# ----------------------- ê°€ê²© ì¡°íšŒ ìœ í‹¸ -----------------------
def _try_extension_variants(fname: str, price_map: Dict[str,int]) -> Optional[int]:
    stem,_ = os.path.splitext(fname)
    for e in [".jpg",".jpeg",".png",".webp",".bmp",".jfif"]:
        key = _norm_name(f"{stem}{e}")
        if key in price_map: return price_map[key]
    return None

def lookup_price_for_filename(filename: str, price_map: Dict[str,int]) -> Optional[int]:
    key = _norm_name(filename)
    if key in price_map: return price_map[key]
    return _try_extension_variants(key, price_map)

# ----------------------- ì¤‘ì•™ê°’/í‰ê·  ê³„ì‚° -----------------------
def median_of(values: List[int]) -> Optional[float]:
    if not values: return None
    xs = sorted(values)
    n = len(xs)
    if n % 2 == 1:
        return float(xs[n//2])
    else:
        return (xs[n//2 - 1] + xs[n//2]) / 2.0

# ----------------------- ë©”ì¸ íŒŒì´í”„ë¼ì¸ -----------------------
def run_sameitem_price(image_path: str = IMAGE_PATH,
                       feats_npy: str = FEATURES_NPY,
                       paths_npy: str = PATHS_NPY,
                       csv_path: str = JOONGNA_CSV,
                       topk: int = TOPK,
                       base_dir: str = IMAGE_BASE_DIR):

    # 0) CSV ë¡œë“œ (ê°€ê²©/ì œëª© ë§µ)
    price_map, title_map = load_meta_maps(csv_path, FILENAME_COL, PRICE_COL, PRODUCT_COL)

    # 1) ìœ ì‚¬ë„ ê²€ìƒ‰
    entries = similar_search(image_path, feats_npy, paths_npy, MODEL_NAME, topk)

    # 2) Top3 í›„ë³´ + ê²½ë¡œ ì¬í•´ê²° + (ì œëª© ë³´ê°•)
    candidates = []
    for c in entries[:3]:
        resolved = resolve_to_base_dir(c["filename"], base_dir)
        nc = dict(c)
        nc["resolved_path"] = resolved
        nc["title"] = title_map.get(c["filename"]) if title_map else None
        candidates.append(nc)

    print("\n=== ğŸ” ìœ ì‚¬ë„ Top3(íŒì • ëŒ€ìƒ) ===")
    for c in candidates:
        print(f"{c['rank']:>2}) sim={c['sim']:.4f} | file={c['filename']} | resolved={c['resolved_path']} | title={c.get('title') or '-'}")

    # 3) LLM ë™ì¼í’ˆ íŒì • (true/false ë°°ì—´)
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key: raise RuntimeError("í™˜ê²½ë³€ìˆ˜ ANTHROPIC_API_KEY ì—†ìŒ")
    client = Anthropic(api_key=api_key)
    judge = SameItemJudgeClaude(client)
    same_flags = judge.judge(image_path, candidates)

    print("\n=== âœ… ë™ì¼í’ˆ íŒì •(JSON) ===")
    print(json.dumps({"same": same_flags}, ensure_ascii=False, indent=2))

    # 4) same=True í›„ë³´ë“¤ì˜ ê°€ê²©ì„ CSVì—ì„œ ì¡°íšŒ
    matched_prices: List[int] = []
    matched_files: List[str] = []
    for c, is_same in zip(candidates, same_flags):
        if is_same:
            fn = _norm_name(c["filename"])
            price = lookup_price_for_filename(fn, price_map)
            if price is not None:
                matched_prices.append(int(price))
                matched_files.append(fn)

    count = len(matched_prices)

    # 5) ê·œì¹™ ì ìš©: 1/3ê°œ â†’ ì¤‘ì•™ê°’, 2ê°œ â†’ í‰ê· , 0ê°œ â†’ íŒë‹¨ ë¶ˆê°€
    print("\n=== ğŸ’° ê¸°ì¤€ê°€ ì‚°ì¶œ ===")
    if count == 0:
        print("ê²°ê³¼: íŒë‹¨ ë¶ˆê°€ (same=Trueê°€ ì—†ê±°ë‚˜, CSVì— ê°€ê²©ì´ ì—†ìŒ)")
        return {"status":"unavailable","reason":"no_same_item_or_price","matched":[]}
    elif count == 1 or count == 3:
        base_price = median_of(matched_prices)
        print(f"same ë§¤ì¹­ {count}ê°œ â†’ ì¤‘ì•™ê°’ ê¸°ì¤€ê°€ = {int(base_price):,}ì›")
    elif count == 2:
        base_price = sum(matched_prices)/2.0
        print(f"same ë§¤ì¹­ 2ê°œ â†’ í‰ê·  ê¸°ì¤€ê°€ = {int(round(base_price)):,}ì›")
    else:
        base_price = median_of(matched_prices)

    print(f"- ë§¤ì¹­ íŒŒì¼: {matched_files}")
    print(f"- ë§¤ì¹­ ê°€ê²©: {[f'{p:,}ì›' for p in matched_prices]}")

    return {
        "status":"ok",
        "matched_count": count,
        "matched_files": matched_files,
        "matched_prices": matched_prices,
        "baseline_price": int(round(base_price))
    }

if __name__ == "__main__":
    run_sameitem_price()
