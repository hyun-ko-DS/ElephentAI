# ai_pricer_sameitem_price.py
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'  # OpenMP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶©ëŒ ë°©ì§€
from typing import Dict, Optional, Tuple, List
import pandas as pd

import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches

import torch
from transformers import CLIPProcessor, CLIPModel

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows í™˜ê²½)
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# ======================= ì‚¬ìš©ì ì„¤ì • =======================
# í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê°œìˆ˜ ì œí•œ (Noneì´ë©´ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬)
MAX_TEST_IMAGES = None  # ì˜ˆ: 10ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì²˜ìŒ 10ê°œë§Œ í…ŒìŠ¤íŠ¸

FEATURES_NPY = "embeddings/train_features_large_patch14-336.npy"
PATHS_NPY    = "embeddings/train_paths_large_patch14-336.npy"
MODEL_NAME   = "openai/clip-vit-large-patch14-336"
TOPK         = 5   # ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜

# test í´ë” ê²½ë¡œ
TEST_DIR = "test"

# ê²°ê³¼ ì €ì¥ ê²½ë¡œ
RESULTS_DIR = "results"
os.makedirs(RESULTS_DIR, exist_ok=True)

# plot ê²°ê³¼ ì €ì¥ ê²½ë¡œ
PLOT_DIR = os.path.join(RESULTS_DIR, MODEL_NAME.replace('/', '_').replace('-', '_'), "plot_result")
os.makedirs(PLOT_DIR, exist_ok=True)

# CSVì—ì„œ íŒŒì¼ëª…â†’ê°€ê²© ë§¤í•‘ (í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
# JOONGNA_CSV  = "records/carbot_data_final.csv"
# FILENAME_COL = "thumbnail_filename"
# PRICE_COL    = "price"
# PRODUCT_COL  = "title"   # (ì„ íƒ: ì—†ìœ¼ë©´ ìë™ ê±´ë„ˆëœ€)

# NORMALIZE_FILENAMES = True
# ==========================================================

# ----------------------- ìœ í‹¸ (í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ) -----------------------
# def _parse_price_to_int(text: str) -> Optional[int]:
#     if text is None: return None
#     t = str(text).strip().replace(",", "").replace("ì›", "").replace("KRW", "")
#     if not re.search(r"[0-9]", t): return None
#     try:
#         return int(float(t))
#     except ValueError:
#         digits = "".join(ch for ch in t if ch.isdigit())
#         return int(digits) if digits else None
# 
# def _norm_name(path_or_name: str) -> str:
#     name = os.path.basename(str(path_or_name)).strip()
#     return name.lower() if NORMALIZE_FILENAMES else name
# 
# def load_meta_maps(csv_path, filename_col, price_col, product_col=None) -> Tuple[Dict[str,int], Optional[Dict[str,str]]]:
#     if not os.path.isfile(csv_path):
#         return {}, None
#     encodings = ("utf-8-sig", "utf-8", "cp949")
#     print(f"CSVì— '{filename_col}', '{price_col}' ì»¬ëŸ¼ì´ í•„ìš”. í˜„ì¬: {fields}")
#         price_map, title_map = {}, {}
#         has_title = product_col in fields if product_col else False
#         for row in reader:
#             raw = row.get(filename_col, "")
#             fname = _norm_name(raw)
#             if not fname: continue
#             price = _parse_price_to_int(row.get(price_col))
#             if price is not None: price_map[fname] = price
#             if has_title: title_map[fname] = str(row.get(product_col, "")).strip()
#         return price_map, (title_map if has_title else None)
#     except UnicodeDecodeError as e:
#         last_err = e
#         continue
#     raise RuntimeError(f"CSV ì¸ì½”ë”© ì‹¤íŒ¨(ì‹œë„: {encodings}) ì›ì¸: {last_err}")

# ----------------------- CLIP ì„ë² ë”© -----------------------
def load_model(model_name: str, device: torch.device):
    model = CLIPModel.from_pretrained(model_name).to(device)
    processor = CLIPProcessor.from_pretrained(model_name)
    model.eval()
    return model, processor

def embed_image(model, processor, img_path, device) -> np.ndarray:
    image = Image.open(img_path).convert("RGB")
    with torch.no_grad():
        inputs = processor(images=image, return_tensors="pt").to(device)
        feat = model.get_image_features(**inputs)
        feat = feat / feat.norm(p=2, dim=-1, keepdim=True)
    return feat.cpu().numpy().astype("float32").flatten()

# ----------------------- ì´ë¯¸ì§€ â†’ Base64 (í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ) -----------------------
# def _resize_to_jpeg_bytes(img: Image.Image, max_side=1024, enhance=False) -> bytes:
#     w,h = img.size
#     scale = min(1.0, max_side / max(w,h))
#     if scale < 1.0: img = img.resize((int(w*scale), int(h*scale)), Image.Resampling.LANCZOS)
#     if enhance:
#         img = ImageEnhance.Contrast(img).enhance(1.3)
#         img = ImageEnhance.Sharpness(img).enhance(1.6)
#         img = ImageEnhance.Brightness(img).enhance(1.05)
#     buf = io.BytesIO(); img.save(buf, format="JPEG", quality=92); return buf.getvalue()
# 
# def _path_to_b64(path: str, enhance=False) -> str:
#     img = Image.open(path).convert("RGB")
#     return base64.b64encode(_resize_to_jpeg_bytes(img, enhance=enhance)).decode("utf-8")

# ----------------------- ë™ì¼í’ˆ íŒì • í”„ë¡¬í”„íŠ¸ (í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ) -----------------------
# SAME_ITEM_PROMPT = """
# You are a product matcher. For each CANDIDATE photo, decide if it is the SAME PRODUCT/MODEL as the QUERY photo.
# Focus on brand/series/character, mold/shape, printed patterns, colorway, scale/size cues, accessories/parts, packaging text or set ID.
# Do NOT be fooled by pose/angle/lighting. If unsure, answer false.
# 
# Return STRICT JSON ONLY, exactly this schema:
# {"same": [true, true, true]}
# 
# Rules:
# - The array order MUST match the order of the CANDIDATE blocks you receive.
# - "same" means same model/edition (not just same category/character).
# - Variant/limited/colorway/set-ID mismatch => false.
# - STRICT JSON only. No extra text.
# """

# ----------------------- Claude í˜¸ì¶œ ë˜í¼ (í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ) -----------------------
# class SameItemJudgeClaude:
#     def __init__(self, client: Anthropic):
#         self.client = client
# 
#     def judge(self, query_path: str, candidates: List[dict]) -> List[bool]:
#         contents = [{"type":"text","text": SAME_ITEM_PROMPT}]
#         contents.append({"type":"text","text": f"QUERY: {os.path.basename(query_path)}"})
#         f"QUERY: {os.path.basename(query_path)}"})
#         contents.append({"type":"image","source":{
#             "type":"base64","media_type":"image/jpeg","data": _path_to_b64(query_path)
#         }})
# 
#         for c in candidates:
#             meta_line = f"CANDIDATE rank={c['rank']} | file={c['filename']} | sim={c['sim']:.4f}"
#             if c.get("title"): metaify(c['filename']} | sim={c['sim']:.4f}"
#             if c.get("title"): meta_line += f" | title={c['title']}"
#             contents.append({"type":"text","text": meta_line})
#             contents.append({"type":"image","source":{
#                 "type":"base64","media_type":"image/jpeg","data": _path_to_b64(c['resolved_path'])
#             }})
# 
#         msg = self.client.messages.create(
#             model=CLAUDE_MODEL,
#             max_tokens=100,  # ì¶œë ¥ì´ ë§¤ìš° ì§§ìŒ
#             temperature=0.1,
#             system="Return STRICT JSON. No extra text.",
#             messages=[{"role":"user","content": contents}]
#         )
# 
#         raw = "".join(b.text for b in msg.content if hasattr(b, "text")).strip()
#         if raw.startswith("```"):
#             raw = raw.strip("`").replace("json","",1).strip()
# 
#         try:
#             data = json.loads(raws):
#             same = list(data.get("same", []))
#             same = [bool(x) for x in same][:len(candidates)]
#             if len(same) < len(candidates):
#                 same += [False] * (len(candidates) - len(same))
#         except Exception:
#             same = [False] * len(candidates)
#         return same

# ----------------------- ìœ ì‚¬ë„ ê²€ìƒ‰ -----------------------
def similar_search(query_img: str, feats_npy: str, paths_npy: str,
                   model_name: str, topk: int=6):
    if not os.path.isfile(query_img): raise FileNotFoundError(f"IMAGE_PATH not found: {query_img}")
    if not os.path.isfile(feats_npy) or not os.path.isfile(paths_npy):
        raise FileNotFoundError("features/paths npy í•„ìš”")

    feats = np.load(feats_npy).astype("float32")
    paths = np.load(paths_npy, allow_pickle=True)
    if feats.ndim!=2 or feats.shape[0]!=len(paths): raise ValueError("features/paths í¬ê¸° ë¶ˆì¼ì¹˜")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model, processor = load_model(model_name, device)

    q = embed_image(model, processor, query_img, device)
    q = q / (np.linalg.norm(q)+1e-9)
    feats = feats / (np.linalg.norm(feats,axis=1,keepdims=True)+1e-9)

    sims = feats @ q
    top_idx = np.argsort(sims)[::-1][:topk]

    entries=[]
    for rank,i in enumerate(top_idx, start=1):
        p = str(paths[i])
        entries.append({
            "rank": rank,
            "path": p,                                  # ì›ë˜ ê²½ë¡œ ë¬¸ìì—´
            "filename": os.path.basename(p),            # basenameë§Œ ì¶”ì¶œ
            "sim": float(sims[i])
        })
    return entries

# ----------------------- ê²½ë¡œ ì¬í•´ê²° (í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ) -----------------------
# def resolve_to_base_dir(filename: str, base_dir: str) -> str:
#     resolved = os.path.join(base_dir, os.path.basename(filename))
#     if not os.path.isfile(resolved):
#         raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {resolved}")
#     return resolved
# 
# ----------------------- ê°€ê²© ì¡°íšŒ ìœ í‹¸ (í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ) -----------------------
# def _try_extension_variants(fname: str, price_map: Dict[str,int]) -> Optional[int]:
#     stem,_ = os.path.splitext(fname)
#     if key in price_map: return price_map[key]
#     return None
# 
# def lookup_price_for_filename(filename: str, price_map: Dict[str,int]) -> Optional[int]:
#     key = _norm_name(filename)
#     if key in price_map: return price_map[key]
#     return _try_extension_variants(key, price_map)
# 
# ----------------------- ì¤‘ì•™ê°’/í‰ê·  ê³„ì‚° (í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ) -----------------------
# def median_of(values: List[int]) -> Optional[float]:
#     if not values: return None
#     xs = sorted(values)
#     n = len(xs)
#     if n % 2 == 1:
#         return float(xs[n//2])
#     else:
#         return (xs[n//2 - 1] + xs[n//2]) / 2.0

# ----------------------- plot ìƒì„± ë° ì €ì¥ -----------------------
def create_and_save_plot(query_image_path: str, search_results: List[Dict], 
                        folder_name: str, filename: str, figsize: Tuple[int, int] = (20, 8)) -> str:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ plotìœ¼ë¡œ ìƒì„±í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    ì…ë ¥:
        query_image_path (str): ì¿¼ë¦¬ ì´ë¯¸ì§€ ê²½ë¡œ
        search_results (List[Dict]): ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        folder_name (str): í…ŒìŠ¤íŠ¸ í´ë”ëª…
        filename (str): í…ŒìŠ¤íŠ¸ íŒŒì¼ëª…
        figsize (Tuple[int, int]): ê·¸ë˜í”„ í¬ê¸°
    
    ì¶œë ¥:
        str: ì €ì¥ëœ plot íŒŒì¼ ê²½ë¡œ
    """
    if not search_results:
        return ""
    
    # ì¿¼ë¦¬ ì´ë¯¸ì§€ ë¡œë“œ
    try:
        query_img: Image.Image = Image.open(query_image_path).convert('RGB')
    except Exception as e:
        print(f"   âš ï¸  ì¿¼ë¦¬ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return ""
    
    # ê²°ê³¼ ì´ë¯¸ì§€ë“¤ ë¡œë“œ
    result_images: List[Image.Image] = []
    for result in search_results:
        try:
            img: Image.Image = Image.open(str(result['path'])).convert('RGB')
            result_images.append(img)
        except Exception as e:
            print(f"   âš ï¸  ê²°ê³¼ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {result['path']} - {e}")
            # ë¹ˆ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´
            result_images.append(Image.new('RGB', (224, 224), color='gray'))
    
    # 1í–‰ìœ¼ë¡œ ì‹œê°í™” (ì¿¼ë¦¬ ì´ë¯¸ì§€ + top k ê²°ê³¼)
    total_images: int = 1 + len(search_results)  # ì¿¼ë¦¬ ì´ë¯¸ì§€ 1ê°œ + ê²°ê³¼ ì´ë¯¸ì§€ë“¤
    fig, axes = plt.subplots(1, total_images, figsize=figsize)
    fig.suptitle(f'Similarity results: {folder_name}/{filename}', fontsize=20, fontweight='bold')
    
    # 1ë²ˆì§¸ ìœ„ì¹˜: ì¿¼ë¦¬ ì´ë¯¸ì§€
    ax = axes[0] if total_images > 1 else axes
    ax.imshow(query_img)
    
    # ì¿¼ë¦¬ ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ í´ë”ëª… ì¶”ì¶œ
    query_path_parts = query_image_path.replace('\\', '/').split('/')
    query_folder_name = query_path_parts[-2] if len(query_path_parts) > 1 else "ì•Œ ìˆ˜ ì—†ìŒ"
    
    ax.set_title(f'Input image\n{query_folder_name}', fontsize=14, fontweight='bold', color='blue')
    ax.axis('off')
    
    # 2ë²ˆì§¸ ìœ„ì¹˜ë¶€í„°: ê²°ê³¼ ì´ë¯¸ì§€ë“¤
    for i, (result, img) in enumerate(zip(search_results, result_images)):
        ax = axes[i + 1] if total_images > 1 else axes
        
        ax.imshow(img)
        
        # ì œëª©ì— ìˆœìœ„, íŒŒì¼ëª…, ìœ ì‚¬ë„ í‘œì‹œ
        title: str = f"#{result['rank']}\n{result['filename']}\nìœ ì‚¬ë„: {result['sim']:.4f}"
        ax.set_title(title, fontsize=10, fontweight='bold')
        ax.axis('off')
        
        # ìœ ì‚¬ë„ì— ë”°ë¥¸ í…Œë‘ë¦¬ ìƒ‰ìƒ ì„¤ì •
        if float(result['sim']) > 0.8:
            color: str = 'green'      # ë†’ì€ ìœ ì‚¬ë„
        elif float(result['sim']) > 0.6:
            color: str = 'orange'     # ì¤‘ê°„ ìœ ì‚¬ë„
        else:
            color: str = 'red'        # ë‚®ì€ ìœ ì‚¬ë„
        
        # í…Œë‘ë¦¬ ì¶”ê°€
        rect = patches.Rectangle((0, 0), img.width-1, img.height-1, 
                                linewidth=3, edgecolor=color, facecolor='none')
        ax.add_patch(rect)
    
    plt.tight_layout()
    
    # plot íŒŒì¼ë¡œ ì €ì¥
    plot_filename = f"{folder_name}_{filename.replace('.', '_')}_similarity.png"
    plot_path = os.path.join(PLOT_DIR, plot_filename)
    
    try:
        plt.savefig(plot_path, dpi=150, bbox_inches='tight', facecolor='white')
        plt.close(fig)  # ë©”ëª¨ë¦¬ ì •ë¦¬
        return plot_path
    except Exception as e:
        print(f"   âš ï¸  plot ì €ì¥ ì‹¤íŒ¨: {e}")
        plt.close(fig)
        return ""

# ----------------------- test í´ë” ì´ë¯¸ì§€ ìˆ˜ì§‘ -----------------------
def collect_test_images(test_dir: str, max_images: Optional[int] = None) -> List[Tuple[str, str]]:
    """
    test í´ë” ë‚´ì˜ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    ì…ë ¥:
        test_dir (str): test í´ë” ê²½ë¡œ
        max_images (Optional[int]): ìµœëŒ€ ì²˜ë¦¬í•  ì´ë¯¸ì§€ ê°œìˆ˜ (Noneì´ë©´ ëª¨ë“  ì´ë¯¸ì§€)
    
    ì¶œë ¥:
        List[Tuple[str, str]]: [(í´ë”ëª…, íŒŒì¼ëª…), ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
    """
    if not os.path.isdir(test_dir):
        print(f"âŒ {test_dir} í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    allowed_exts = {".jpg", ".jpeg", ".png", ".webp", ".bmp"}
    test_images = []
    
    # test í´ë” ë‚´ì˜ ëª¨ë“  í•˜ìœ„ í´ë”ì™€ íŒŒì¼ì„ ìŠ¤ìº”
    for root, dirs, files in os.walk(test_dir):
        for file in files:
            if os.path.splitext(file)[1].lower() in allowed_exts:
                # ìƒëŒ€ ê²½ë¡œë¡œ í´ë”ëª…ê³¼ íŒŒì¼ëª… ì¶”ì¶œ
                rel_path = os.path.relpath(root, test_dir)
                if rel_path == ".":
                    folder_name = "root"
                else:
                    folder_name = rel_path.replace("\\", "/")
                
                test_images.append((folder_name, file))
                
                # ìµœëŒ€ ê°œìˆ˜ ì œí•œ í™•ì¸
                if max_images and len(test_images) >= max_images:
                    print(f"âš ï¸  ìµœëŒ€ {max_images}ê°œ ì´ë¯¸ì§€ë¡œ ì œí•œí•©ë‹ˆë‹¤.")
                    break
        
        if max_images and len(test_images) >= max_images:
            break
    
    # ì •ë ¬í•˜ì—¬ ì¼ê´€ëœ ê²°ê³¼ ë³´ì¥
    test_images.sort()
    return test_images

# ----------------------- ìë™í™”ëœ ìœ ì‚¬ë„ ê²€ìƒ‰ ë° ê²°ê³¼ ì €ì¥ -----------------------
def run_automated_similarity_search():
    """
    test í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ì— ëŒ€í•´ ìë™ìœ¼ë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    print("ğŸš€ ìë™í™”ëœ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œì‘")
    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ í´ë”: {TEST_DIR}")
    print(f"ğŸ” ìµœëŒ€ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {MAX_TEST_IMAGES or 'ëª¨ë“  ì´ë¯¸ì§€'}")
    print(f"ğŸ“Š ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {TOPK}")
    
    # 1. test í´ë” ì´ë¯¸ì§€ ìˆ˜ì§‘
    print("\nğŸ“‚ test í´ë” ì´ë¯¸ì§€ ìˆ˜ì§‘ ì¤‘...")
    test_images = collect_test_images(TEST_DIR, MAX_TEST_IMAGES)
    
    if not test_images:
        print("âŒ test í´ë”ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… {len(test_images)}ê°œì˜ ì´ë¯¸ì§€ ë°œê²¬")
    
    # 2. ì„ë² ë”© íŒŒì¼ í™•ì¸ ë° ë¡œë“œ
    if not os.path.isfile(FEATURES_NPY) or not os.path.isfile(PATHS_NPY):
        print(f"âŒ ì„ë² ë”© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FEATURES_NPY}, {PATHS_NPY}")
        print("   ë¨¼ì € python embeddings_train.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì„ë² ë”©ì„ ìƒì„±í•˜ì„¸ìš”.")
        return
    
    try:
        print("ğŸ“‚ ì„ë² ë”© íŒŒì¼ ë¡œë“œ ì¤‘...")
        feats = np.load(FEATURES_NPY).astype("float32")
        paths = np.load(PATHS_NPY, allow_pickle=True)
        
        if feats.ndim != 2 or feats.shape[0] != len(paths):
            raise ValueError("features/paths íŒŒì¼ í¬ê¸°ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        print(f"âœ… ì„ë² ë”© íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {feats.shape[0]}ê°œ ë²¡í„°, {feats.shape[1]}ì°¨ì›")
            
    except Exception as e:
        print(f"âŒ ì„ë² ë”© íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # 3. CLIP ëª¨ë¸ ë¡œë“œ
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  Device: {device}")
    
    try:
        print("ğŸ”§ CLIP ëª¨ë¸ ë¡œë“œ ì¤‘...")
        model, processor = load_model(MODEL_NAME, device)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # 4. ê° í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•´ ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
    results = []
    print(f"\nğŸ” {len(test_images)}ê°œ ì´ë¯¸ì§€ì— ëŒ€í•´ ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
    
    for i, (folder_name, filename) in enumerate(test_images, 1):
        print(f"\n[{i}/{len(test_images)}] ì²˜ë¦¬ ì¤‘: {folder_name}/{filename}")
        
        # ì „ì²´ ê²½ë¡œ êµ¬ì„±
        full_path = os.path.join(TEST_DIR, folder_name, filename)
        
        try:
            # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
            search_results = similar_search(full_path, FEATURES_NPY, PATHS_NPY, MODEL_NAME, TOPK)
            
            if search_results:
                # ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ
                top_result = search_results[0]
                top_similar_path = str(top_result['path'])
                similarity_score = top_result['sim']
                
                # ê²½ë¡œì—ì„œ í´ë”ëª… ì¶”ì¶œ (top_similar_predictì— í´ë”ëª… ì €ì¥)
                top_path_parts = top_similar_path.replace('\\', '/').split('/')
                top_folder_name = top_path_parts[-2] if len(top_path_parts) > 1 else "ì•Œ ìˆ˜ ì—†ìŒ"
                
                print(f"   âœ… Top1 ìœ ì‚¬ë„: {top_folder_name} (ìœ ì‚¬ë„: {similarity_score:.4f})")
                
                # plot ìƒì„± ë° ì €ì¥
                plot_path = create_and_save_plot(full_path, search_results, folder_name, filename)
                if plot_path:
                    print(f"   ğŸ“Š plot ì €ì¥ ì™„ë£Œ: {os.path.basename(plot_path)}")
                
                # ê²°ê³¼ ì €ì¥
                results.append({
                    'test_folder': folder_name,
                    'test_filename': filename,
                    'top_similar_predict': top_folder_name,
                    'similarity_score': similarity_score,
                    'plot_path': plot_path
                })
            else:
                print(f"   âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                results.append({
                    'test_folder': folder_name,
                    'test_filename': filename,
                    'top_similar_predict': 'N/A',
                    'top_similarity': 0.0,
                    'full_path': full_path,
                    'plot_path': ''
                })
                
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            results.append({
                'test_folder': folder_name,
                'test_filename': filename,
                'top_similar_predict': 'ERROR',
                'top_similarity': 0.0,
                'full_path': full_path,
                'plot_path': ''
            })
    
    # 5. ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥
    if results:
        # MODEL_NAMEì—ì„œ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ë¶€ë¶„ ì¶”ì¶œ
        model_name_clean = MODEL_NAME.replace('/', '_').replace('-', '_')
        csv_filename = f"{model_name_clean}_result.csv"
        csv_path = os.path.join(RESULTS_DIR, csv_filename)
        
        # DataFrame ìƒì„± ë° ì €ì¥
        df = pd.DataFrame(results)
        
        # ìš”ì²­ëœ í˜•ì‹ìœ¼ë¡œ ì»¬ëŸ¼ ì •ë¦¬ (similarity_score í¬í•¨)
        output_df = df[['test_folder', 'test_filename', 'top_similar_predict', 'similarity_score', 'plot_path']].copy()
        
        try:
            output_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_path}")
            print(f"ğŸ“Š ì´ {len(results)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ")
            
            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            print(f"\nğŸ“‹ ê²°ê³¼ ìš”ì•½:")
            print(f"   - í…ŒìŠ¤íŠ¸ í´ë” ìˆ˜: {output_df['test_folder'].nunique()}")
            print(f"   - ì´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(output_df)}")
            print(f"   - ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {len(output_df[output_df['top_similar_predict'] != 'ERROR'])}")
            print(f"   - plot ìƒì„± ì™„ë£Œ: {len(output_df[output_df['plot_path'] != ''])}")
            print(f"   - plot ì €ì¥ ê²½ë¡œ: {PLOT_DIR}")
            print(f"   - CSV ì €ì¥ ê²½ë¡œ: {csv_path}")
            
        except Exception as e:
            print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
    else:
        print("âŒ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ----------------------- ë©”ì¸ íŒŒì´í”„ë¼ì¸ (í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ) -----------------------
# def run_sameitem_price(image_path: str = None,
#                        feats_npy: str = FEATURES_NPY,
#                        paths_npy: str = PATHS_NPY,
#                        csv_path: str = JOONGNA_CSV,
#                        topk: int = TOPK,
#                        base_dir: str = None):
#     """
#     ê¸°ì¡´ í•¨ìˆ˜ëŠ” ìœ ì§€í•˜ë˜, ì´ë¯¸ì§€ ê²½ë¡œê°€ Noneì´ë©´ ìë™í™”ëœ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
#     """
#     if image_path is None:
#         # ìë™í™”ëœ ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
#         run_automated_similarity_search()
#         return
#     
#     # ê¸°ì¡´ ë¡œì§ (ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬)
#     # ... ê¸°ì¡´ ì½”ë“œ ìœ ì§€ ...

if __name__ == "__main__":
    # ìë™í™”ëœ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰
    run_automated_similarity_search()
