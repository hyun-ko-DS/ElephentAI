"""
ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œìŠ¤í…œ
=======================

ì…ë ¥ ìŠ¤í™:
---------
1. INPUT_DIR: "test" í´ë”ì— ê²€ìƒ‰í•  ì´ë¯¸ì§€ íŒŒì¼ë“¤ (.jpg, .jpeg, .png, .webp, .bmp)
2. USED_DIR: "train" í´ë”ì— ë¹„êµ ëŒ€ìƒ ì´ë¯¸ì§€ë“¤
3. FEATURES_NPY: "embeddings/train_features_base_patch16.npy" - train í´ë” ì´ë¯¸ì§€ë“¤ì˜ CLIP ì„ë² ë”© ë²¡í„°
4. PATHS_NPY: "embeddings/train_paths_base_patch16.npy" - train í´ë” ì´ë¯¸ì§€ë“¤ì˜ íŒŒì¼ ê²½ë¡œ
5. PRODUCTS_CSV: "records/carbot_data_final.csv" - ìƒí’ˆ ì •ë³´ (ìƒí’ˆëª…, ì •ê°€, ì¤‘ê³ ê°€, ë§í¬)
6. MODEL_NAME: 'openai/clip-vit-base-patch16' - CLIP ëª¨ë¸ëª…
7. TOPK: 5 - ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ ê°œìˆ˜

ì¶œë ¥ ìŠ¤í™:
---------
1. ì‹œê°í™”: ì¿¼ë¦¬ ì´ë¯¸ì§€ + top k ìœ ì‚¬ ì´ë¯¸ì§€ë“¤ì„ 1í–‰ìœ¼ë¡œ í‘œì‹œ
2. í…ìŠ¤íŠ¸: ê° ì´ë¯¸ì§€ì˜ ìˆœìœ„, íŒŒì¼ëª…, í´ë”ëª…, ìœ ì‚¬ë„, ì •ê°€, ì¤‘ê³ ê°€, ë§í¬
3. ë°˜í™˜ê°’: ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ (return_results=Trueì¼ ë•Œ)

ì‚¬ìš©ë²•:
------
search_by_image_name("ì´ë¯¸ì§€íŒŒì¼ëª….jpg")  # ì‹œê°í™” í¬í•¨
get_search_results_only("ì´ë¯¸ì§€íŒŒì¼ëª….jpg")  # ê²°ê³¼ë§Œ ë°˜í™˜
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'  # OpenMP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶©ëŒ ë°©ì§€
import gc
import warnings
from typing import List, Dict, Tuple, Optional, Union, Any
warnings.filterwarnings('ignore')

from PIL import Image
import torch
from transformers import CLIPProcessor, CLIPModel

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows í™˜ê²½)
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# ==================== ì‹œìŠ¤í…œ ì„¤ì • ====================
INPUT_DIR: str = "test"                     # ê²€ìƒ‰í•  ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” (test í´ë”)
USED_DIR: str = "train"                     # ë¹„êµ ëŒ€ìƒ ì´ë¯¸ì§€ë“¤ì´ ìˆëŠ” í´ë” (train í´ë”)
FEATURES_NPY: str = "embeddings/train_features_large_patch14-336.npy"  # train í´ë” ì´ë¯¸ì§€ë“¤ì˜ ì„ë² ë”© ë²¡í„°
PATHS_NPY: str = "embeddings/train_paths_large_patch14-336.npy"        # train í´ë” ì´ë¯¸ì§€ë“¤ì˜ íŒŒì¼ ê²½ë¡œ
PRODUCTS_CSV: str = "records/carbot_data_final.csv"     # ìƒí’ˆ ì •ë³´ CSV íŒŒì¼
MODEL_NAME: str = 'openai/clip-vit-large-patch14-336'  # CLIP ëª¨ë¸ëª… (embeddings_train.pyì™€ ë™ì¼)
TOPK: int = 5                              # ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ ê°œìˆ˜

# ==================== ë™ì¼í’ˆ íŒì • í”„ë¡¬í”„íŠ¸ ====================
SAME_ITEM_PROMPT: str = """
You are a product matcher. For each CANDIDATE photo, decide if it is the SAME PRODUCT/MODEL as the QUERY photo.
Focus on brand/series/character, mold/shape, printed patterns, colorway, scale/size cues, accessories/parts, packaging text or set ID.
Do NOT be fooled by pose/angle/lighting. If unsure, answer false.

Return STRICT JSON ONLY, exactly this schema:
{"same": [true, true, true]}

Rules:
- The array order MUST match the order of the CANDIDATE blocks you receive.
- "same" means same model/edition (not just same category/character).
- Variant/limited/colorway/set-ID mismatch => false.
- STRICT JSON only. No extra text.
"""

# ==================== í•µì‹¬ í•¨ìˆ˜ë“¤ ====================

def load_model(model_name: str, device: torch.device) -> Tuple[CLIPModel, CLIPProcessor]:
    """
    CLIP ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    ì…ë ¥:
        model_name (str): CLIP ëª¨ë¸ëª… (ì˜ˆ: 'openai/clip-vit-large-patch14')
        device (torch.device): GPU ë˜ëŠ” CPU ë””ë°”ì´ìŠ¤
    
    ì¶œë ¥:
        Tuple[CLIPModel, CLIPProcessor]: CLIP ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ê°ì²´
    """
    model = CLIPModel.from_pretrained(model_name).to(device)
    processor = CLIPProcessor.from_pretrained(model_name)
    model.eval()
    return model, processor

def embed_image(model: CLIPModel, processor: CLIPProcessor, img_path: str, device: torch.device) -> np.ndarray:
    """
    ì´ë¯¸ì§€ì˜ CLIP ì„ë² ë”© ë²¡í„°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    ì…ë ¥:
        model (CLIPModel): CLIP ëª¨ë¸ ê°ì²´
        processor (CLIPProcessor): CLIP í”„ë¡œì„¸ì„œ ê°ì²´
        img_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        device (torch.device): GPU ë˜ëŠ” CPU ë””ë°”ì´ìŠ¤
    
    ì¶œë ¥:
        np.ndarray: ì„ë² ë”© ë²¡í„° (ì •ê·œí™”ë¨)
                   - base ëª¨ë¸: 512ì°¨ì›
                   - large ëª¨ë¸: 768ì°¨ì›
    """
    image = Image.open(img_path).convert("RGB")
    with torch.no_grad():
        inputs = processor(images=image, return_tensors="pt").to(device)
        feat = model.get_image_features(**inputs)
        feat = feat / feat.norm(p=2, dim=-1, keepdim=True)  # L2 ì •ê·œí™”
    return feat.cpu().numpy().astype("float32").flatten()

def list_input_images() -> List[str]:
    """
    input í´ë”ì˜ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    ì…ë ¥: ì—†ìŒ
    
    ì¶œë ¥:
        List[str]: ì§€ì›ë˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ìë¥¼ ê°€ì§„ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸
    """
    if not os.path.isdir(INPUT_DIR):
        print(f"âŒ {INPUT_DIR} í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    allowed_exts: set = {".jpg", ".jpeg", ".png", ".webp", ".bmp"}
    images: List[str] = []
    
    for f in os.listdir(INPUT_DIR):
        if os.path.splitext(f)[1].lower() in allowed_exts:
            images.append(f)
    
    images.sort()
    return images

def load_products_info() -> Dict[str, Dict[str, Any]]:
    """
    carbot_data_final.csv íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ìƒí’ˆ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    ì…ë ¥: ì—†ìŒ
    
    ì¶œë ¥:
        Dict[str, Dict[str, Any]]: {ìƒí’ˆëª…: {retail_price, used_price_avg, retail_link}} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    try:
        if os.path.isfile(PRODUCTS_CSV):
            df: pd.DataFrame = pd.read_csv(PRODUCTS_CSV)
            products_dict: Dict[str, Dict[str, Any]] = {}
            
            for _, row in df.iterrows():
                product_name: str = str(row['product_name']).strip()
                retail_price: Any = row['retail_price']
                used_price_avg: Any = row['used_price_avg']
                retail_link: str = str(row['retail_link']).strip()
                
                products_dict[product_name] = {
                    'retail_price': retail_price,
                    'used_price_avg': used_price_avg,
                    'retail_link': retail_link
                }
            
            print(f"âœ… {len(products_dict)}ê°œì˜ ìƒí’ˆ ì •ë³´ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            return products_dict
        else:
            print(f"âš ï¸  {PRODUCTS_CSV} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {}
    except Exception as e:
        print(f"âŒ ìƒí’ˆ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

def get_product_info_from_path(image_path: str, products_dict: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
    """
    ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ í´ë”ëª…ì„ ì¶”ì¶œí•˜ì—¬ í•´ë‹¹ ìƒí’ˆì˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    ì…ë ¥:
        image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        products_dict (Dict[str, Dict[str, Any]]): ìƒí’ˆ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    
    ì¶œë ¥:
        Dict[str, Any]: ìƒí’ˆ ì •ë³´ ë˜ëŠ” ê¸°ë³¸ê°’
    """
    # ê²½ë¡œì—ì„œ í´ë”ëª… ì¶”ì¶œ (ë§ˆì§€ë§‰ í´ë”ëª…ì´ ìƒí’ˆëª…)
    path_parts = image_path.replace('\\', '/').split('/')
    folder_name = path_parts[-2] if len(path_parts) > 1 else ""
    
    # í´ë”ëª…ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ (í—¬ë¡œì¹´ë´‡_ ì ‘ë‘ì‚¬ ì œê±°)
    if folder_name.startswith("í—¬ë¡œì¹´ë´‡_"):
        product_name = folder_name[6:]  # "í—¬ë¡œì¹´ë´‡_" ì œê±°
    else:
        product_name = folder_name
    
    # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
    if product_name in products_dict:
        return products_dict[product_name]
    
    # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (í´ë”ëª…ì´ ìƒí’ˆëª…ì˜ ì¼ë¶€ì¸ ê²½ìš°)
    for key, info in products_dict.items():
        if product_name in key or key in product_name:
            return info
    
    # ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
    return {
        'retail_price': 'ê°€ê²© ì •ë³´ ì—†ìŒ',
        'used_price_avg': 'ì¤‘ê³ ê°€ ì •ë³´ ì—†ìŒ',
        'retail_link': 'ë§í¬ ì—†ìŒ'
    }

def search_similar_images(query_image_path: str, features: np.ndarray, paths: np.ndarray, 
                         model: CLIPModel, processor: CLIPProcessor, device: torch.device, 
                         top_k: int = 5) -> List[Dict[str, Union[int, float, str]]]:
    """
    ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    ì…ë ¥:
        query_image_path (str): ê²€ìƒ‰í•  ì´ë¯¸ì§€ ê²½ë¡œ
        features (np.ndarray): ëª¨ë“  ì´ë¯¸ì§€ì˜ ì„ë² ë”© ë²¡í„° (N x ì°¨ì›)
        paths (np.ndarray): ëª¨ë“  ì´ë¯¸ì§€ì˜ íŒŒì¼ ê²½ë¡œ
        model (CLIPModel): CLIP ëª¨ë¸ ê°ì²´
        processor (CLIPProcessor): CLIP í”„ë¡œì„¸ì„œ ê°ì²´
        device (torch.device): GPU ë˜ëŠ” CPU ë””ë°”ì´ìŠ¤
        top_k (int): ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ê°œìˆ˜
    
    ì¶œë ¥:
        List[Dict[str, Union[int, float, str]]]: ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
            [{'rank': 1, 'path': 'ê²½ë¡œ', 'similarity': 0.8, 'filename': 'íŒŒì¼ëª…'}, ...]
    """
    try:
        # ì¿¼ë¦¬ ì´ë¯¸ì§€ ì„ë² ë”© ê³„ì‚°
        q: np.ndarray = embed_image(model, processor, query_image_path, device)
        
        # ì°¨ì› í™•ì¸ ë° ì¡°ì •
        query_dim = q.shape[0]
        features_dim = features.shape[1]
        
        print(f"ğŸ” ì°¨ì› ì •ë³´: ì¿¼ë¦¬ ì´ë¯¸ì§€ {query_dim}ì°¨ì›, ì €ì¥ëœ ì„ë² ë”© {features_dim}ì°¨ì›")
        
        if query_dim != features_dim:
            print(f"âš ï¸  ì°¨ì› ë¶ˆì¼ì¹˜ ê°ì§€! ì¿¼ë¦¬: {query_dim}ì°¨ì›, ì €ì¥ëœ ì„ë² ë”©: {features_dim}ì°¨ì›")
            print("   ì €ì¥ëœ ì„ë² ë”©ê³¼ ë™ì¼í•œ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.")
            return []
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°ì„ ìœ„í•œ ì •ê·œí™”
        q = q / (np.linalg.norm(q) + 1e-9)
        features_norm: np.ndarray = features / (np.linalg.norm(features, axis=1, keepdims=True) + 1e-9)
        
        # ìœ ì‚¬ë„ ê³„ì‚° (ì •ê·œí™”ëœ ë²¡í„°ì˜ ë‚´ì  = ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
        sims: np.ndarray = features_norm @ q
        top_idx: np.ndarray = np.argsort(sims)[::-1][:top_k]  # ìœ ì‚¬ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        
        # ê²°ê³¼ ìƒì„±
        results: List[Dict[str, Union[int, float, str]]] = []
        for rank, i in enumerate(top_idx, start=1):
            results.append({
                'rank': rank,
                'path': str(paths[i]),
                'similarity': float(sims[i]),
                'filename': os.path.basename(str(paths[i]))
            })
        
        return results
        
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def visualize_search_results_with_query(query_image_path: str, results: List[Dict[str, Union[int, float, str]]], 
                                      products_dict: Dict[str, Any], figsize: Tuple[int, int] = (20, 8)) -> None:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤. (ì¿¼ë¦¬ ì´ë¯¸ì§€ + ê²°ê³¼ ì´ë¯¸ì§€ë“¤)
    
    ì…ë ¥:
        query_image_path (str): ì¿¼ë¦¬ ì´ë¯¸ì§€ ê²½ë¡œ
        results (List[Dict[str, Union[int, float, str]]]): ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        products_dict (Dict[str, Any]): ìƒí’ˆ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        figsize (Tuple[int, int]): ê·¸ë˜í”„ í¬ê¸° (ê°€ë¡œ, ì„¸ë¡œ)
    
    ì¶œë ¥: ì—†ìŒ (matplotlib ê·¸ë˜í”„ í‘œì‹œ)
    """
    if not results:
        print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì¿¼ë¦¬ ì´ë¯¸ì§€ ë¡œë“œ
    try:
        query_img: Image.Image = Image.open(query_image_path).convert('RGB')
        print(f"âœ… ì¿¼ë¦¬ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {os.path.basename(query_image_path)}")
    except Exception as e:
        print(f"âŒ ì¿¼ë¦¬ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # ê²°ê³¼ ì´ë¯¸ì§€ë“¤ ë¡œë“œ
    result_images: List[Image.Image] = []
    for result in results:
        try:
            img: Image.Image = Image.open(str(result['path'])).convert('RGB')
            result_images.append(img)
        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {result['path']} - {e}")
            # ë¹ˆ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´
            result_images.append(Image.new('RGB', (224, 224), color='gray'))
    
    # 1í–‰ìœ¼ë¡œ ì‹œê°í™” (ì¿¼ë¦¬ ì´ë¯¸ì§€ + top k ê²°ê³¼)
    total_images: int = 1 + len(results)  # ì¿¼ë¦¬ ì´ë¯¸ì§€ 1ê°œ + ê²°ê³¼ ì´ë¯¸ì§€ë“¤
    fig, axes = plt.subplots(1, total_images, figsize=figsize)
    fig.suptitle(f'Similarity results: {os.path.basename(query_image_path)}', fontsize=20, fontweight='bold')
    
    # 1ë²ˆì§¸ ìœ„ì¹˜: ì¿¼ë¦¬ ì´ë¯¸ì§€
    ax = axes[0] if total_images > 1 else axes
    ax.imshow(query_img)
    ax.set_title('Input image', fontsize=14, fontweight='bold', color='blue')
    ax.axis('off')
    
    # 2ë²ˆì§¸ ìœ„ì¹˜ë¶€í„°: ê²°ê³¼ ì´ë¯¸ì§€ë“¤
    for i, (result, img) in enumerate(zip(results, result_images)):
        ax = axes[i + 1] if total_images > 1 else axes
        
        ax.imshow(img)
        
        # ê°€ê²© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        price_info: Dict[str, Any] = get_product_info_from_path(str(result['path']), products_dict)
        
        # ì œëª©ì— ìˆœìœ„, íŒŒì¼ëª…, ìœ ì‚¬ë„, ê°€ê²© í‘œì‹œ
        retail_price = price_info['retail_price'] if price_info['retail_price'] != 'ê°€ê²© ì •ë³´ ì—†ìŒ' else 'N/A'
        used_price = price_info['used_price_avg'] if price_info['used_price_avg'] != 'ì¤‘ê³ ê°€ ì •ë³´ ì—†ìŒ' else 'N/A'
        
        title: str = f"#{result['rank']}\n{result['filename']}\nìœ ì‚¬ë„: {result['similarity']:.4f}\nì •ê°€: {retail_price}\nì¤‘ê³ ê°€: {used_price}"
        ax.set_title(title, fontsize=10, fontweight='bold')
        ax.axis('off')
        
        # ìœ ì‚¬ë„ì— ë”°ë¥¸ í…Œë‘ë¦¬ ìƒ‰ìƒ ì„¤ì •
        if float(result['similarity']) > 0.8:
            color: str = 'green'      # ë†’ì€ ìœ ì‚¬ë„
        elif float(result['similarity']) > 0.6:
            color: str = 'orange'     # ì¤‘ê°„ ìœ ì‚¬ë„
        else:
            color: str = 'red'        # ë‚®ì€ ìœ ì‚¬ë„
        
        # í…Œë‘ë¦¬ ì¶”ê°€
        rect = patches.Rectangle((0, 0), img.width-1, img.height-1, 
                                linewidth=3, edgecolor=color, facecolor='none')
        ax.add_patch(rect)
    
    plt.tight_layout()
    plt.show()
    
    # í…ìŠ¤íŠ¸ ê²°ê³¼ë„ ì¶œë ¥
    print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ (ìƒìœ„ {len(results)}ê°œ)")
    print("=" * 100)
    for result in results:
        price_info: Dict[str, Any] = get_product_info_from_path(str(result['path']), products_dict)
        
        # ê²½ë¡œì—ì„œ í´ë”ëª…ê³¼ íŒŒì¼ëª… ì¶”ì¶œ
        path_parts = str(result['path']).replace('\\', '/').split('/')
        folder_name = path_parts[-2] if len(path_parts) > 1 else "ì•Œ ìˆ˜ ì—†ìŒ"
        filename = result['filename']
        
        # ê°€ê²© ì •ë³´ í¬ë§·íŒ…
        retail_price = price_info['retail_price'] if price_info['retail_price'] != 'ê°€ê²© ì •ë³´ ì—†ìŒ' else 'N/A'
        used_price = price_info['used_price_avg'] if price_info['used_price_avg'] != 'ì¤‘ê³ ê°€ ì •ë³´ ì—†ìŒ' else 'N/A'
        
        print(f"{result['rank']:2d}. {filename}")
        print(f"    ğŸ“ í´ë”: {folder_name}")
        print(f"    ğŸ’° ì •ê°€: {retail_price}")
        print(f"    ğŸ’° ì¤‘ê³ ê°€: {used_price}")
        print(f"    ğŸ“ ìœ ì‚¬ë„: {result['similarity']:.4f}")
        print(f"    ğŸ”— ë§í¬: {price_info['retail_link']}")
        print("-" * 80)

def search_by_image_name(image_name: str, return_results: bool = False) -> Optional[List[Dict[str, Union[int, float, str]]]]:
    """
    ì´ë¯¸ì§€ëª…ì„ ì…ë ¥ë°›ì•„ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
    
    ì…ë ¥:
        image_name (str): ê²€ìƒ‰í•  ì´ë¯¸ì§€ íŒŒì¼ëª…
        return_results (bool): Trueë©´ ê²°ê³¼ ë°˜í™˜, Falseë©´ ì‹œê°í™”ë§Œ
    
    ì¶œë ¥:
        Optional[List[Dict[str, Union[int, float, str]]]]: return_results=Trueì¼ ë•Œ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸, Falseì¼ ë•Œ None
    """
    
    print(f" ê²€ìƒ‰ ì‹œì‘: {image_name}")
    
    # ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ í™•ì¸
    query_image_path: str = os.path.join(INPUT_DIR, image_name)
    if not os.path.isfile(query_image_path):
        print(f"âŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {query_image_path}")
        print(f"\n {INPUT_DIR} í´ë”ì˜ ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¯¸ì§€ë“¤:")
        input_images: List[str] = list_input_images()
        for i, img in enumerate(input_images[:20], 1):
            print(f"  {i:2d}. {img}")
        if len(input_images) > 20:
            print(f"  ... ë° {len(input_images) - 20}ê°œ ë”")
        return None
    
    # ì„ë² ë”© íŒŒì¼ í™•ì¸
    if not os.path.isfile(FEATURES_NPY) or not os.path.isfile(PATHS_NPY):
        print("âŒ used í´ë”ì˜ ì„ë² ë”© íŒŒì¼ì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.")
        print("   python embeddings.py")
        return None
    
    # ìƒí’ˆ ì •ë³´ ë¡œë“œ
    products_dict: Dict[str, Any] = load_products_info()
    
    # ì„ë² ë”© íŒŒì¼ ë¡œë“œ
    try:
        print("ğŸ“‚ ì„ë² ë”© íŒŒì¼ ë¡œë“œ ì¤‘...")
        feats: np.ndarray = np.load(FEATURES_NPY).astype("float32")
        paths: np.ndarray = np.load(PATHS_NPY, allow_pickle=True)
        
        if feats.ndim != 2 or feats.shape[0] != len(paths):
            raise ValueError("features/paths íŒŒì¼ í¬ê¸°ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        print(f"âœ… ì„ë² ë”© íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {feats.shape[0]}ê°œ ë²¡í„°, {feats.shape[1]}ì°¨ì›")
            
    except Exception as e:
        print(f"âŒ ì„ë² ë”© íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    # ëª¨ë¸ ë¡œë“œ
    device: torch.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  Device: {device}")
    
    try:
        print(" CLIP ëª¨ë¸ ë¡œë“œ ì¤‘...")
        model, processor = load_model(MODEL_NAME, device)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
    print(f" '{image_name}' ì´ë¯¸ì§€ë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘... (ìƒìœ„ {TOPK}ê°œ ê²°ê³¼)")
    results: List[Dict[str, Union[int, float, str]]] = search_similar_images(query_image_path, feats, paths, model, processor, device, TOPK)
    
    if results:
        print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼ ë°œê²¬")
        
        # ê°€ê²© ì •ë³´ë¥¼ ê²°ê³¼ì— ì¶”ê°€
        for result in results:
            result['price'] = get_product_info_from_path(str(result['path']), products_dict)['retail_price']
        
        if return_results:
            # ê²°ê³¼ë§Œ ë¦¬í„´ (ì‹œê°í™” ì œì™¸)
            print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ (ìƒìœ„ {len(results)}ê°œ)")
            print("=" * 100)
            for result in results:
                price_info: Dict[str, Any] = get_product_info_from_path(str(result['path']), products_dict)
                
                # ê²½ë¡œì—ì„œ í´ë”ëª…ê³¼ íŒŒì¼ëª… ì¶”ì¶œ
                path_parts = str(result['path']).replace('\\', '/').split('/')
                folder_name = path_parts[-2] if len(path_parts) > 1 else "ì•Œ ìˆ˜ ì—†ìŒ"
                filename = result['filename']
                
                # ê°€ê²© ì •ë³´ í¬ë§·íŒ…
                retail_price = price_info['retail_price'] if price_info['retail_price'] != 'ê°€ê²© ì •ë³´ ì—†ìŒ' else 'N/A'
                used_price = price_info['used_price_avg'] if price_info['used_price_avg'] != 'ì¤‘ê³ ê°€ ì •ë³´ ì—†ìŒ' else 'N/A'
                
                print(f"{result['rank']:2d}. {filename}")
                print(f"    ğŸ“ í´ë”: {folder_name}")
                print(f"    ğŸ’° ì •ê°€: {retail_price}")
                print(f"    ğŸ’° ì¤‘ê³ ê°€: {used_price}")
                print(f"    ğŸ“ ìœ ì‚¬ë„: {result['similarity']:.4f}")
                print(f"    ğŸ”— ë§í¬: {price_info['retail_link']}")
                print("-" * 80)
            
            print(f"\n ê²°ê³¼ë¥¼ ë¦¬í„´í•©ë‹ˆë‹¤. (ì´ {len(results)}ê°œ)")
            return results
        else:
            # ìƒˆë¡œìš´ ì‹œê°í™” ë°©ì‹ ì‚¬ìš© (ì¿¼ë¦¬ ì´ë¯¸ì§€ + ê²°ê³¼ ì´ë¯¸ì§€ë“¤)
            visualize_search_results_with_query(query_image_path, results, products_dict)
            return None
    else:
        print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

# ==================== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ====================

def get_search_results_only(image_name: str) -> Optional[List[Dict[str, Union[int, float, str]]]]:
    """
    ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ (ì‹œê°í™” ì œì™¸)
    
    ì…ë ¥:
        image_name (str): ê²€ìƒ‰í•  ì´ë¯¸ì§€ íŒŒì¼ëª…
    
    ì¶œë ¥:
        Optional[List[Dict[str, Union[int, float, str]]]]: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None
    """
    print(f" {image_name} ê²€ìƒ‰ ì‹œì‘ (ê²°ê³¼ë§Œ ë°˜í™˜)")
    return search_by_image_name(image_name, return_results=True)

def test_search() -> Optional[List[Dict[str, Union[int, float, str]]]]:
    """
    ê²€ìƒ‰ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
    
    ì…ë ¥: ì—†ìŒ
    
    ì¶œë ¥:
        Optional[List[Dict[str, Union[int, float, str]]]]: í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë˜ëŠ” None
    """
    print("ğŸ§ª ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # input í´ë”ì˜ ì´ë¯¸ì§€ í™•ì¸
    input_images: List[str] = list_input_images()
    if not input_images:
        print("âŒ input í´ë”ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    print(f"ğŸ“ input í´ë”ì—ì„œ {len(input_images)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
    test_image: str = input_images[0]
    print(f"ğŸ” í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {test_image}")
    
    # ê²€ìƒ‰ ì‹¤í–‰
    results: Optional[List[Dict[str, Union[int, float, str]]]] = get_search_results_only(test_image)
    
    if results:
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ! {len(results)}ê°œ ê²°ê³¼ ë°˜í™˜")
        return results
    else:
        print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return None

def show_image(image_path: str, title: Optional[str] = None, figsize: Tuple[int, int] = (5, 3)) -> None:
    """
    ì´ë¯¸ì§€ë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜
    
    ì…ë ¥:
        image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        title (Optional[str]): ì´ë¯¸ì§€ ì œëª©
        figsize (Tuple[int, int]): ê·¸ë˜í”„ í¬ê¸°
    
    ì¶œë ¥: ì—†ìŒ (matplotlib ê·¸ë˜í”„ í‘œì‹œ)
    """
    try:
        img: Image.Image = Image.open(image_path)
        plt.figure(figsize=figsize)
        plt.imshow(img)
        plt.axis('off')
        if title:
            plt.title(title)
        else:
            plt.title(image_path)
        plt.show()
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")

def clear_gpu_memory() -> None:
    """
    GPU ë©”ëª¨ë¦¬ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
    
    ì…ë ¥: ì—†ìŒ
    
    ì¶œë ¥: ì—†ìŒ
    """
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        print("ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
    
    gc.collect()
    print("ğŸ§¹ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")

def check_gpu_memory() -> Tuple[float, float, float]:
    """
    GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•©ë‹ˆë‹¤.
    
    ì…ë ¥: ì—†ìŒ
    
    ì¶œë ¥:
        Tuple[float, float, float]: (í• ë‹¹ëœ ë©”ëª¨ë¦¬, ì˜ˆì•½ëœ ë©”ëª¨ë¦¬, ì´ ë©”ëª¨ë¦¬) (GB ë‹¨ìœ„)
    """
    if torch.cuda.is_available():
        allocated: float = torch.cuda.memory_allocated() / 1024**3  # GB
        reserved: float = torch.cuda.memory_reserved() / 1024**3    # GB
        total: float = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
        
        print(f"ğŸ–¥ï¸  GPU ë©”ëª¨ë¦¬ ìƒíƒœ:")
        print(f"   í• ë‹¹ë¨: {allocated:.2f} GB")
        print(f"   ì˜ˆì•½ë¨: {reserved:.2f} GB")
        print(f"   ì´ ìš©ëŸ‰: {total:.2f} GB")
        print(f"   ì‚¬ìš© ê°€ëŠ¥: {total - reserved:.2f} GB")
        
        return allocated, reserved, total
    else:
        print("ğŸ’» GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return 0.0, 0.0, 0.0

# ==================== ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ====================

if __name__ == "__main__":
    check_gpu_memory()
    clear_gpu_memory()
    # ì˜ˆì‹œ ê²€ìƒ‰ ì‹¤í–‰ (test í´ë”ì˜ ì´ë¯¸ì§€ë¡œ train í´ë” ê²€ìƒ‰)
    # search_by_image_name("thunder_0108.webp")  # test í´ë”ì˜ thunder ì´ë¯¸ì§€
    # search_by_image_name("í—¬ë¡œì¹´ë´‡_ê³¨ë“œë ‰ìŠ¤/thunder_0109.webp")    # test í´ë”ì˜ thunder ì´ë¯¸ì§€
    search_by_image_name("í—¬ë¡œì¹´ë´‡_[í•œì •íŒ]_í¬ë¦¬ìŠ¤íƒˆì¹´ë´‡_ìŠ¤í†°_X/thunder_0752.webp") 
    # get_search_results_only("thunder_1322.webp")  # test í´ë”ì˜ thunder ì´ë¯¸ì§€

    clear_gpu_memory()